\documentclass{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage[polish]{babel}
\usepackage[margin=1in]{geometry}

\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}

\usepackage{booktabs} % Lepsza jakość tabel
\usepackage{graphicx}
\usepackage{float}

\usepackage{siunitx} 
\sisetup{
    output-exponent-marker = e,
    bracket-numbers = false,
    group-separator = {\,}, 
    scientific-notation = true
}

% Inne
\usepackage{hyperref} 
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
    pdftitle={Obliczenia Naukowe - Lista 1},
    pdfauthor={Wojciech Typer},
}

\title{Sprawozdanie z Laboratorium\\Obliczenia Naukowe - Lista 1}
\author{Karol Wziątek}

\begin{document}
\maketitle
\section*{Zadanie 1}

\subsection{Epsilon maszynowy (\textit{macheps})}

Epsilonem maszynowym \textit{macheps} nazywamy najmniejszą liczbę dodatnią taką, że w arytmetyce zmiennoprzecinkowej zachodzi \(1.0 + \text{macheps} > 1.0\). 

Jest to miara precyzji obliczeń, która określa odległość od liczby 1.0 do następnej reprezentowalnej liczby maszynowej. Im mniejszy epsilon, tym więcej bitów przeznaczonych na mantysę w danym typie zmiennoprzecinkowym, co z kolei przekłada się na wyższą precyzję tej arytmetyki.

\begin{table}[H]
\centering
\label{tab:epsilon}
\begin{tabular}{llll}
\toprule
\textbf{Typ danych} & \textbf{Wartość z \texttt{float.h} (GCC)} & \textbf{Wartość z \texttt{eps(T)} (Julia)} & \textbf{Wartość wyznaczona iteracyjnie} \\
\midrule
\texttt{Float16} & \num{9.7656e-4} & \num{0.000977} & \num{0.000977} \\
\texttt{Float32} & \num{1.192093e-07} & \num{1.1920929e-7} & \num{1.1920929e-7} \\
\texttt{Float64} & \num{2.220446e-16} & \num{2.220446049250313e-16} & \num{2.220446049250313e-16} \\
\bottomrule
\end{tabular}
\end{table}

Wartości \textit{macheps} wyznaczone iteracyjnie są zgodne z wynikami funkcji \texttt{eps(T)}. Wyznaczone zostały poprzez dzielenie przez 2 liczy 1.0 w danej arytmetyce aż T(1.0) + eta == T(1.0), gdzie T to kolejno Float16, Float32, Float64.

\textbf{Związek między macheps a $\epsilon$}: $\text{macheps} = 2 \cdot \epsilon$ - na podstawie wartości podanych na wykładzie.

\subsection{Najmniejsza dodatnia liczba maszynowa (\textit{eta})}

Liczba \textit{eta} (\(\eta\)) to najmniejsza dodatnia wartość, jaką można reprezentować w danym standardzie zmiennoprzecinkowym.

\begin{itemize}
    \item \textbf{Związek z \textit{MIN\textsubscript{sub}}}: Liczba \textit{eta} jest tożsama z \textit{MIN\textsubscript{sub}}, czyli najmniejszą możliwą do reprezentowania dodatnią liczbą subnormalną. W języku Julia wartość tę można uzyskać za pomocą funkcji \texttt{nextfloat(T(0.0))}.
    \item \textbf{Związek z \textit{MIN\textsubscript{nor}}}: Funkcja \texttt{floatmin(T)} zwraca najmniejszą dodatnią liczbę \textbf{znormalizowaną}, znaną jako \textit{MIN\textsubscript{nor}}. Dla odpowiednio \texttt{Float32} i \texttt{Float64} wartości te wynoszą: \num{1.1754944e-38} i \num{2.2250738585072014e-308}, co zgadza się z wartościami podanymi na wykładzie.
\end{itemize}

\begin{table}[H]
\centering
\label{tab:eta}
\begin{tabular}{lll}
\toprule
\textbf{Typ danych} & \textbf{Wartość z \texttt{nextfloat(T(0.0))}} & \textbf{Wartość wyznaczona iteracyjnie} \\
\midrule
\texttt{Float16} & \num{6.0e-8} & \num{6.0e-8} \\
\texttt{Float32} & \num{1.0e-45} & \num{1.0e-45} \\ 
\texttt{Float64} & \num{5.0e-324} & \num{5.0e-324} \\
\bottomrule
\end{tabular}
\end{table}

Wartości \textit{eta} wyznaczone iteracyjnie są zgodne z wynikami funkcji \texttt{nextfloat(T(0.0))}. Wyznaczone zostały poprzez dzielenie przez 2 liczy 1.0 w danej arytmetyce aż T(0.0) + eta == T(0.0), gdzie T to kolejno Float16, Float32, Float64

\subsection{Największa wartość skończona (\textit{MAX})}

Liczba \textit{MAX} to najwyższa wartość, którą można zapisać w danym typie zmiennoprzecinkowym. 

\begin{table}[H]
\centering
\label{tab:max}
\begin{tabular}{llll}
\toprule
\textbf{Typ danych} & \textbf{Wartość z \texttt{float.h} (GCC)} & \textbf{Wartość wyznaczona iteracyjnie} & \textbf{Wartość z \texttt{floatmax(T)} (Julia)} \\
\midrule
\texttt{Float16} & --- & \num{6.55e4} & \num{6.55e4} \\
\texttt{Float32} & \num{3.4028234663852886e+38} & \num{3.4028235e38} & \num{3.4028235e38} \\
\texttt{Float64} & \num{1.7976931348623157e+308} & \num{1.7976931348623157e308} & \num{1.7976931348623157e308} \\
\bottomrule
\end{tabular}
\end{table}
Jak widać w tabeli, wartości wyznaczone iteracyjnie są zgodne z pozostałymi źródłami. 
Aby doświadczalnie wyznaczyć \textit{MAX} trzeba mnożyć T(1.0) przez dwa aż do uzyskania INF. 
Bierzemy ostatnią wartość przed uzyskaniem INF i zamieniamy wszystkie jej 0 na 1, gdzie T to kolejno Float16, Float32, Float64.


\section*{Zadanie 2}
W tym zadaniu należy sprawdzić, czy metoda Kahana poprawnie wyznacza epsilon maszynowy dla typów Float16, Float32, Float64.
\begin{table}[H]
\centering
\label{tab:kahan_comparison}
\begin{tabular}{lll}
\toprule
\textbf{Typ danych} & \textbf{Wartość z metody Kahana} & \textbf{Wartość z \texttt{eps(T)} (Julia)} \\
\midrule
\texttt{Float16} & \num{-0.000977} & \num{0.000977} \\
\texttt{Float32} & \num{1.1920929e-7} & \num{1.1920929e-7} \\
\texttt{Float64} & \num{-2.220446049250313e-16} & \num{2.220446049250313e-16} \\
\bottomrule


\end{tabular}
\end{table}
\paragraph{Wnioski}
\sloppy 
Z powyższej tabeli widzimy, że wyrażenie Kahana niepoprawnie wyznaczało epsilon maszynowy dla wszystkich typów zmiennopozycyjnych.
W celu otrzymania prawidłowego rozwiązania należy na wynik nałożyć wartość bezwzględną. Błędy w bicie znaku wynikają z reprezentacji rozwinięcia binarnego ułamka $\frac{4}{3}$.
\fussy % Przywróć domyślne ustawienia

\section*{Zadanie 3}

Sprawdź eksperymentalnie w języku Julia, że w arytmetyce Float64 (arytmetyce double
w standarcie IEEE 754) liczby zmiennopozycyjne są równomiernie rozmieszczone w [1, 2] z
krokiem δ = 2−52. Innymi słowy, każda liczba zmiennopozycyjna x pomiędzy 1 i 2 może
być przedstawione następująco x = 1 + kδ w tej arytmetyce, gdzie k = 1, 2, . . . , 252 − 1 i
δ = 2−52.

\begin{itemize}
    \item \textbf{Przedział \([1, 2]\):} W arytmetyce \texttt{double}, liczby zmiennoprzecinkowe są rozmieszczone równomiernie na przedziale \([1, 2]\) z krokiem równym $\delta = 2^{-52}$. Oznacza to, że każda kolejna liczba na tym przedziale różni się od poprzedniej o dokładnie $\delta$. Sprawdzono to eksperymentalnie: 1000-krotnie generując losową liczbę z tego przedziału i wyznaczając kolejną liczbę maszynową za pomocą funkcji \texttt{nextfloat()}, różnica między nimi zawsze była równa $\delta$.

    \item \textbf{Przedział \([0.5, 1]\):} Dla tego przedziału krok wynosi $\delta = 2^{-53}$. Każda liczba może być przedstawiona jako: $x = 1 + k \cdot \delta$, gdzie $k$ jest liczbą całkowitą, a $\delta = 2^{-53}$.

    \item \textbf{Przedział \([2, 4]\):} W tym przypadku krok jest większy i wynosi $\delta = 2^{-51}$. Dla tego przedziału każda liczba może być przedstawiona jako: $x = 2 + k \cdot \delta$, gdzie $\delta = 2^{-51}$.
\end{itemize}

Powyższe eksperymenty potwierdzają, że w arytmetyce zmiennoprzecinkowej liczby są rozmieszczone gęściej bliżej zera i rzadziej w miarę oddalania się od niego. Zjawisko to nie jest przypadkowe, lecz wynika bezpośrednio ze sposobu, w jaki liczby są reprezentowane w formacie IEEE 754.
\section*{Zadanie 4}
W tym zadaniu trzeba znaleść eksperymentalnie najmniejszą liczbę x w arytmetyce $Float64$, $1<x<2$, taką że:
\[
    x \otimes (1/x)) \neq 1
\]
Aby ją wyznaczyć, zaczynamy od liczby $1$ i zwiększamy ją przy użyciu funkcji $nextfloat$ aż do momentu, gdy warunek przestanie być spełniony. W ten sposób otrzymujemy:
\[
    x = 1.000000057228997
\]
Jest to najmniejsza liczba w arytmetyce $Float64$, spełniająca podany warunek.

\section*{Zadanie 5}
W tym zadaniu należy zaimplementować 4 różne algorytmy obliczania iloczynu skalarnego dwóch wektorów w arytmetyce $Float32$ oraz $Float64$ i porównać ich wyniki między sobą oraz z wynikiem dokładnym.\\
Implementacja algorytmów:
\begin{enumerate}
    \item \textbf{w przód} -- $\sum_{i=1}^{n} x_i y_i$
    \item \textbf{w tył} -- $\sum_{i=n}^{1} x_i y_i$
    \item \textbf{sortowanie rosnąco} -- sortujemy iloczyny $x_i y_i$ rosnąco (w zależności od wartości bezwzględnej, osobno dodajemy ujemne i dodatnie)
    \item \textbf{sortowanie malejąco} -- analogicznie jak wyżej, ale sortujemy malejąco
\end{enumerate}
Po przeprowadzeniu eksperymentów na wektorach:
\[
    x = [2.718281828, -3.141592654, 1.414213562, 0.5772156649, 0.3010299957]
\]
\[
    y = [1486.2497, 878366.9879, -22.37492, 4773714.647, 0.000185049]
\]
oraz obliczeniu dokładnego wyniku iloczynu skalarnego (wynoszącego $-1.00657107000000 \cdot 10^{-11}$) otrzymujemy następujące wyniki:
%Float32:
%Wynik wPrzod: -4.9994430e-01
%Wynik wTyl: -4.5434570e-01
%Wynik ascSort: -5.0000000e-01
%Wynik descSort: -5.0000000e-01

%Float64:
%Wynik wPrzod: 1.025188136829667e-10
%Wynik wTyl: -1.564330887049437e-10
%Wynik ascSort: 0.000000000000000e+00
%Wynik descSort: 0.000000000000000e+00
\begin{table}[h!]
    \centering
    \begin{tabular}{|c|c|c|}
        \hline
        Algorytm & Wynik Float32 & Wynik Float64 \\
        \hline
        1. & $-4.9994430 \cdot 10^{-1}$ & $1.025188136829667 \cdot 10^{-10}$ \\
        \hline
        2. & $-4.5434570 \cdot 10^{-1}$ & $-1.564330887049437 \cdot 10^{-10}$ \\
        \hline
        3. & $-5.0000000 \cdot 10^{-1}$ & $0.000000000000000 \cdot 10^{0}$ \\
        \hline
        4. & $-5.0000000 \cdot 10^{-1}$ & $0.000000000000000 \cdot 10^{0}$ \\
        \hline
    \end{tabular}
    \label{tab:iloczyn}
\end{table}\\
Jak widać, wyniki są obarczone dużym błędem, a różne algorytmy dają różne wyniki, co potwierdza, że kolejność wykonywania działań ma znaczenie. Błąd jest tym większy im mniejsza jest mantysa - Float64 lepiej na tym wychodzi.

\section*{Zadanie 6}
W tym zadaniu należało obliczyć wartości funkcji: $f(x) = \sqrt{x^2 + 1} - 1 \text{ oraz } g(x) = \frac{x^2}{\sqrt{x^2 + 1} + 1}$
Iterując po wartościach $x = 8^{-1}, 8^{-2}, 8^{-3}, \ldots$ aż do momentu, gdy wynik obliczeń przestanie się zmieniać (w arytmetyce $Float64$) otrzymujemy następujące wyniki:
%i = 1, f(x) = 7.7822185373186414e-03, g(x) = 7.7822185373187065e-03
%i = 2, f(x) = 1.2206286282867573e-04, g(x) = 1.2206286282875901e-04
%i = 3, f(x) = 1.9073468138230965e-06, g(x) = 1.9073468138265659e-06
%i = 4, f(x) = 2.9802321943606103e-08, g(x) = 2.9802321943606116e-08
%i = 5, f(x) = 4.6566128730773926e-10, g(x) = 4.6566128719931904e-10
%i = 6, f(x) = 7.2759576141834259e-12, g(x) = 7.2759576141569561e-12
%i = 7, f(x) = 1.1368683772161603e-13, g(x) = 1.1368683772160957e-13
%i = 8, f(x) = 1.7763568394002505e-15, g(x) = 1.7763568394002489e-15
%i = 9, f(x) = 0.0000000000000000e+00, g(x) = 2.7755575615628914e-17
%i = 10, f(x) = 0.0000000000000000e+00, g(x) = 4.3368086899420177e-19
%i = 170, f(x) = 0.0000000000000000e+00, g(x) = 4.4501477170144028e-308
%i = 171, f(x) = 0.0000000000000000e+00, g(x) = 6.9533558078350043e-310
%i = 172, f(x) = 0.0000000000000000e+00, g(x) = 1.0864618449742194e-311
%i = 173, f(x) = 0.0000000000000000e+00, g(x) = 1.6975966327722179e-313
%i = 174, f(x) = 0.0000000000000000e+00, g(x) = 2.6524947387065904e-315
%i = 175, f(x) = 0.0000000000000000e+00, g(x) = 4.1445230292290475e-317
%i = 176, f(x) = 0.0000000000000000e+00, g(x) = 6.4758172331703867e-319
%i = 177, f(x) = 0.0000000000000000e+00, g(x) = 1.0118464426828729e-320
%i = 178, f(x) = 0.0000000000000000e+00, g(x) = 1.5810100666919889e-322
%i = 179, f(x) = 0.0000000000000000e+00, g(x) = 0.0000000000000000e+00
%i = 180, f(x) = 0.0000000000000000e+00, g(x) = 0.0000000000000000e+00
\begin{table}[h!]
    \centering
    \begin{tabular}{|c|c|c|}
        \hline
        x & f(x) & g(x) \\
        \hline
        $8^{-1}$ & $7.7822185373186414 \cdot 10^{-3}$ & $7.7822185373187065 \cdot 10^{-3}$ \\
        \hline
        $8^{-2}$ & $1.2206286282867573 \cdot 10^{-4}$ & $1.2206286282875901 \cdot 10^{-4}$ \\
        \hline
        $8^{-3}$ & $1.9073468138230965 \cdot 10^{-6}$ & $1.9073468138265659 \cdot 10^{-6}$ \\
        \hline
        $8^{-4}$ & $2.9802321943606103 \cdot 10^{-8}$ & $2.9802321943606116 \cdot 10^{-8}$ \\
        \hline
        $8^{-5}$ & $4.6566128730773926 \cdot 10^{-10}$ & $4.6566128719931904 \cdot 10^{-10}$ \\
        \hline
        $8^{-6}$ & $7.2759576141834259 \cdot 10^{-12}$ & $7.2759576141569561 \cdot 10^{-12}$ \\
        \hline
        $8^{-7}$ & $1.1368683772161603 \cdot 10^{-13}$ & $1.1368683772160957 \cdot 10^{-13}$ \\
        \hline
        $8^{-8}$ & $1.7763568394002505 \cdot 10^{-15}$ & $1.7763568394002489 \cdot 10^{-15}$ \\
        \hline
        $8^{-9}$ & $0.0000000000000000 \cdot 10^{0}$ & $2.7755575615628914 \cdot 10^{-17}$ \\
        \hline
        \dots & \dots & \dots \\
        \hline
        $8^{-170}$ & $0.0000000000000000 \cdot 10^{0}$ & $4.4501477170144028 \cdot 10^{-308}$ \\
        \hline
        $8^{-171}$ & $0.0000000000000000 \cdot 10^{0}$ & $6.9533558078350043 \cdot 10^{-310}$ \\
        \hline
        $8^{-172}$ & $0.0000000000000000 \cdot 10^{0}$ & $1.0864618449742194 \cdot 10^{-311}$ \\
        \hline
        $8^{-173}$ & $0.0000000000000000 \cdot 10^{0}$ & $1.6975966327722179 \cdot 10^{-313}$ \\
        \hline
        $8^{-174}$ & $0.0000000000000000 \cdot 10^{0}$ & $2.6524947387065904 \cdot 10^{-315}$ \\
        \hline
        $8^{-175}$ & $0.0000000000000000 \cdot 10^{0}$ & $4.1445230292290475 \cdot 10^{-317}$ \\
        \hline
        $8^{-176}$ & $0.0000000000000000 \cdot 10^{0}$ & $6.4758172331703867 \cdot 10^{-319}$ \\
        \hline
        $8^{-177}$ & $0.0000000000000000 \cdot 10^{0}$ & $1.0118464426828729 \cdot 10^{-320}$ \\
        \hline
        $8^{-178}$ & $0.0000000000000000 \cdot 10^{0}$ & $1.5810100666919889 \cdot 10^{-322}$ \\
        \hline
        $8^{-179}$ & $0.0000000000000000 \cdot 10^{0}$ & $0.0000000000000000 \cdot 10^{0}$ \\
        \hline
    \end{tabular}
    \label{tab:f_g}
\end{table}\\
\pagebreak

Mimo, że funkcje $f$ oraz $g$ są algebraicznie takie same, to Julia zwraca inne rezultaty. Dzieje się tak, ponieważ odejmowanie od siebie dwóch bardzo bliskich liczb generuje duży błąd.

Im mniejszy $x$, tym wartość $\sqrt{x^2 + 1}$ jest bliższa 1. Tak więc operacja $\sqrt{x^2 + 1} - 1$ jest operacją odejmowania dwóch bardzo bliskich sobie liczb, co powoduje powstanie dużego błędu numerycznego. W przypadku funkcji $g$ nie występuje odejmowanie bliskich sobie liczb, przez co błąd numeryczny jest znacznie mniejszy.

\subsection*{Zadanie 7}
W zadaniu należało obliczyć przybliżoną wartość pochodnej funkcji $f(x) = \sin x + \cos 3x$ w punkcie $x_0 = 1$ za pomocą wzoru:
\[
    f'(x_0) \approx \tilde f'(x_0) = \frac{f(x_0 + h) - f(x_0)}{h}
\]
Obliczając wartości funkcji dla kolejnych wartości $h = 2^{-n}, n \in \{0,1,2,\ldots,54\}$ otrzymujemy następujące wyniki:
%i h aprox_f' error
%0 1.000000e+00 8.694677e-01 7.525254e-01
%1 1.500000e+00 4.730729e-01 3.561306e-01
% 2 1.250000e+00 2.998405e-01 1.828982e-01
% 3 1.125000e+00 2.507786e-01 1.338363e-01
% 4 1.062500e+00 2.381337e-01 1.211914e-01
% 5 1.031250e+00 2.349485e-01 1.180062e-01
% 6 1.015625e+00 2.341506e-01 1.172084e-01
% 7 1.007812e+00 2.339511e-01 1.170088e-01
% 8 1.003906e+00 2.339012e-01 1.169589e-01
% 9 1.001953e+00 2.338887e-01 1.169464e-01
%10 1.000977e+00 2.338856e-01 1.169433e-01
%11 1.000488e+00 2.338848e-01 1.169425e-01
%12 1.000244e+00 2.338846e-01 1.169423e-01
%13 1.000122e+00 2.338846e-01 1.169423e-01
%14 1.000061e+00 2.338846e-01 1.169423e-01
%15 1.000031e+00 2.338846e-01 1.169423e-01
%16 1.000015e+00 2.338846e-01 1.169423e-01
%17 1.000008e+00 2.338846e-01 1.169423e-01
%18 1.000004e+00 2.338846e-01 1.169423e-01
%19 1.000002e+00 2.338846e-01 1.169423e-01
%20 1.000001e+00 2.338846e-01 1.169423e-01
%21 1.000000e+00 2.338846e-01 1.169423e-01
%22 1.000000e+00 2.338846e-01 1.169423e-01
%23 1.000000e+00 2.338846e-01 1.169423e-01
%24 1.000000e+00 2.338846e-01 1.169423e-01
%25 1.000000e+00 2.338846e-01 1.169423e-01
%26 1.000000e+00 2.338846e-01 1.169423e-01
%27 1.000000e+00 2.338846e-01 1.169423e-01
%28 1.000000e+00 2.338846e-01 1.169423e-01
%29 1.000000e+00 2.338846e-01 1.169423e-01
%30 1.000000e+00 2.338845e-01 1.169422e-01
%31 1.000000e+00 2.338846e-01 1.169423e-01
%32 1.000000e+00 2.338843e-01 1.169421e-01
%33 1.000000e+00 2.338839e-01 1.169416e-01
%34 1.000000e+00 2.338848e-01 1.169425e-01
%35 1.000000e+00 2.338829e-01 1.169406e-01
%36 1.000000e+00 2.338867e-01 1.169444e-01
%37 1.000000e+00 2.338715e-01 1.169292e-01
%38 1.000000e+00 2.339172e-01 1.169750e-01
%39 1.000000e+00 2.338257e-01 1.168834e-01
%40 1.000000e+00 2.337646e-01 1.168224e-01
%41 1.000000e+00 2.338867e-01 1.169444e-01
%42 1.000000e+00 2.338867e-01 1.169444e-01
%43 1.000000e+00 2.333984e-01 1.164562e-01
%44 1.000000e+00 2.363281e-01 1.193858e-01
%45 1.000000e+00 2.304688e-01 1.135265e-01
%46 1.000000e+00 2.265625e-01 1.096202e-01
%47 1.000000e+00 2.343750e-01 1.174327e-01
%48 1.000000e+00 2.187500e-01 1.018077e-01
%49 1.000000e+00 3.125000e-01 1.955577e-01
%50 1.000000e+00 1.250000e-01 8.057718e-03
%51 1.000000e+00 2.500000e-01 1.330577e-01
%52 1.000000e+00 -5.000000e-01 6.169423e-01
%53 1.000000e+00 1.000000e+00 8.830577e-01
%54 1.000000e+00 0.000000e+00 1.169423e-01
\begin{table}[h!]
    \centering
    \begin{tabular}{|c|c|c|}
        \hline
        h & $\tilde{f}'(x_0)$ & Błąd bezwzględny \\
        \hline
        $2^{0}$ & $8.694677 \cdot 10^{-1}$ & $7.525254 \cdot 10^{-1}$ \\
        \hline
        $2^{-1}$ & $4.730729 \cdot 10^{-1}$ & $3.561306 \cdot 10^{-1}$ \\
        \hline
        $2^{-2}$ & $2.998405 \cdot 10^{-1}$ & $1.828982 \cdot 10^{-1}$ \\
        \hline
        $2^{-3}$ & $2.507786 \cdot 10^{-1}$ & $1.338363 \cdot 10^{-1}$ \\
        \hline
        $2^{-4}$ & $2.381337 \cdot 10^{-1}$ & $1.211914 \cdot 10^{-1}$ \\
        \hline
        $2^{-5}$ & $2.349485 \cdot 10^{-1}$ & $1.180062 \cdot 10^{-1}$ \\
        \hline
        $2^{-6}$ & $2.341506 \cdot 10^{-1}$ & $1.172084 \cdot 10^{-1}$ \\
        \hline
        $2^{-7}$ & $2.339511 \cdot 10^{-1}$ & $1.170088 \cdot 10^{-1}$ \\
        \hline
        $2^{-8}$ & $2.339012 \cdot 10^{-1}$ & $1.169589 \cdot 10^{-1}$ \\
        \hline
        $2^{-9}$ & $2.338887 \cdot 10^{-1}$ & $1.169464 \cdot 10^{-1}$ \\
        \hline
        $2^{-10}$ & $2.338856 \cdot 10^{-1}$ & $1.169433 \cdot 10^{-1}$ \\
        \hline
        $2^{-11}$ & $2.338848 \cdot 10^{-1}$ & $1.169425 \cdot 10^{-1}$ \\
        \hline
        $2^{-12}$ & $2.338846 \cdot 10^{-1}$ & $1.169423 \cdot 10^{-1}$ \\
        \hline
        $2^{-13}$ & $2.338846 \cdot 10^{-1}$ & $1.169423 \cdot 10^{-1}$ \\
        \hline
        \dots & \dots & \dots \\
        \hline
        $2^{-50}$ & $1.250000 \cdot 10^{-1}$ & $8.057718 \cdot 10^{-3}$ \\
        \hline
        $2^{-51}$ & $2.500000 \cdot 10^{-1}$ & $1.330577 \cdot 10^{-1}$ \\
        \hline
        $2^{-52}$ & $-5.000000 \cdot 10^{-1}$ & $6.169423 \cdot 10^{-1}$ \\
        \hline
        $2^{-53}$ & $1.000000 \cdot 10^{0}$ & $8.830577 \cdot 10^{-1}$ \\
        \hline
        $2^{-54}$ & $0.000000 \cdot 10^{0}$ & $1.169423 \cdot 10^{-1}$ \\
        \hline
    \end{tabular}
    \label{tab:pochodna}
\end{table}\\
Początkowo, gdy zmniejszamy wartość $h$, błąd w przybliżeniu pochodnej również maleje. Jednak po pewnym punkcie (około $h = 2^{-27}$) zaczyna on ponownie rosnąć, mimo że h staje się mniejsze. Dzieje się tak, ponieważ w tym zakresie zaczyna przeważać błąd zaokrągleń. Przy bardzo małych $h$ różnica $f(x0+h)$ $-$ $f(x0)$ jest tak mała, że ograniczona precyzja arytmetyki zmiennoprzecinkowej powoduje znaczne zniekształcenia, co skutkuje większym błędem w obliczeniach.

\end{document}